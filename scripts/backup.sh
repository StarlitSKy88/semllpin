#!/bin/bash

# SmellPin Êï∞ÊçÆÂ∫ìÂ§á‰ªΩÂíåÊÅ¢Â§çËÑöÊú¨
# ÊîØÊåÅËá™Âä®Â§á‰ªΩ„ÄÅÊâãÂä®Â§á‰ªΩ„ÄÅÊÅ¢Â§çÁ≠âÂäüËÉΩ

set -e

# È¢úËâ≤ÂÆö‰πâ
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# ÈÖçÁΩÆÂèòÈáè
BACKUP_DIR="./backups"
DATE=$(date +%Y%m%d_%H%M%S)
DB_CONTAINER="smellpin-postgres"
DB_NAME="smellpin_prod"
DB_USER="smellpin"
RETENTION_DAYS=30
S3_BUCKET="${BACKUP_S3_BUCKET:-}"
S3_ACCESS_KEY="${BACKUP_S3_ACCESS_KEY:-}"
S3_SECRET_KEY="${BACKUP_S3_SECRET_KEY:-}"

# ÂàõÂª∫Â§á‰ªΩÁõÆÂΩï
mkdir -p "$BACKUP_DIR"

# Êï∞ÊçÆÂ∫ìÂ§á‰ªΩ
backup_database() {
    local backup_file="$BACKUP_DIR/database_$DATE.sql"
    
    log_info "ÂºÄÂßãÂ§á‰ªΩÊï∞ÊçÆÂ∫ì..."
    
    # Ê£ÄÊü•Êï∞ÊçÆÂ∫ìÂÆπÂô®ÊòØÂê¶ËøêË°å
    if ! docker ps | grep -q "$DB_CONTAINER"; then
        log_error "Êï∞ÊçÆÂ∫ìÂÆπÂô® $DB_CONTAINER Êú™ËøêË°å"
        exit 1
    fi
    
    # ÊâßË°åÂ§á‰ªΩ
    docker exec "$DB_CONTAINER" pg_dump -U "$DB_USER" -d "$DB_NAME" --verbose --clean --no-owner --no-privileges > "$backup_file"
    
    if [ $? -eq 0 ]; then
        # ÂéãÁº©Â§á‰ªΩÊñá‰ª∂
        gzip "$backup_file"
        backup_file="${backup_file}.gz"
        
        local file_size=$(du -h "$backup_file" | cut -f1)
        log_success "Êï∞ÊçÆÂ∫ìÂ§á‰ªΩÂÆåÊàê: $backup_file (Â§ßÂ∞è: $file_size)"
        
        echo "$backup_file"
    else
        log_error "Êï∞ÊçÆÂ∫ìÂ§á‰ªΩÂ§±Ë¥•"
        exit 1
    fi
}

# Êñá‰ª∂Â§á‰ªΩ
backup_files() {
    local backup_file="$BACKUP_DIR/files_$DATE.tar.gz"
    
    log_info "ÂºÄÂßãÂ§á‰ªΩÊñá‰ª∂..."
    
    # Â§á‰ªΩ‰∏ä‰º†Êñá‰ª∂
    if [ -d "uploads" ]; then
        tar -czf "$backup_file" uploads/
        
        local file_size=$(du -h "$backup_file" | cut -f1)
        log_success "Êñá‰ª∂Â§á‰ªΩÂÆåÊàê: $backup_file (Â§ßÂ∞è: $file_size)"
        
        echo "$backup_file"
    else
        log_warning "uploadsÁõÆÂΩï‰∏çÂ≠òÂú®ÔºåË∑≥ËøáÊñá‰ª∂Â§á‰ªΩ"
    fi
}

# ÈÖçÁΩÆÂ§á‰ªΩ
backup_config() {
    local backup_file="$BACKUP_DIR/config_$DATE.tar.gz"
    
    log_info "ÂºÄÂßãÂ§á‰ªΩÈÖçÁΩÆÊñá‰ª∂..."
    
    # Â§á‰ªΩÈÖçÁΩÆÊñá‰ª∂
    tar -czf "$backup_file" \
        --exclude='node_modules' \
        --exclude='dist' \
        --exclude='logs' \
        --exclude='backups' \
        --exclude='.git' \
        .env* docker-compose*.yml nginx/ ssl/ monitoring/ || true
    
    local file_size=$(du -h "$backup_file" | cut -f1)
    log_success "ÈÖçÁΩÆÂ§á‰ªΩÂÆåÊàê: $backup_file (Â§ßÂ∞è: $file_size)"
    
    echo "$backup_file"
}

# ‰∏ä‰º†Âà∞S3
upload_to_s3() {
    local file="$1"
    local s3_key="smellpin/$(basename "$file")"
    
    if [ -z "$S3_BUCKET" ] || [ -z "$S3_ACCESS_KEY" ] || [ -z "$S3_SECRET_KEY" ]; then
        log_warning "S3ÈÖçÁΩÆ‰∏çÂÆåÊï¥ÔºåË∑≥Ëøá‰∫ëÁ´ØÂ§á‰ªΩ"
        return
    fi
    
    log_info "‰∏ä‰º†Â§á‰ªΩÂà∞S3: $s3_key"
    
    # ‰ΩøÁî®AWS CLI‰∏ä‰º†
    if command -v aws &> /dev/null; then
        AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY" \
        AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY" \
        aws s3 cp "$file" "s3://$S3_BUCKET/$s3_key"
        
        log_success "S3‰∏ä‰º†ÂÆåÊàê: s3://$S3_BUCKET/$s3_key"
    else
        log_warning "AWS CLIÊú™ÂÆâË£ÖÔºåË∑≥ËøáS3‰∏ä‰º†"
    fi
}

# Ê∏ÖÁêÜÊóßÂ§á‰ªΩ
cleanup_old_backups() {
    log_info "Ê∏ÖÁêÜ $RETENTION_DAYS Â§©ÂâçÁöÑÂ§á‰ªΩ..."
    
    # Âà†Èô§Êú¨Âú∞ÊóßÂ§á‰ªΩ
    find "$BACKUP_DIR" -name "*.sql.gz" -mtime +$RETENTION_DAYS -delete
    find "$BACKUP_DIR" -name "*.tar.gz" -mtime +$RETENTION_DAYS -delete
    
    # Ê∏ÖÁêÜS3ÊóßÂ§á‰ªΩ
    if [ -n "$S3_BUCKET" ] && command -v aws &> /dev/null; then
        local cutoff_date=$(date -d "$RETENTION_DAYS days ago" +%Y-%m-%d)
        
        AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY" \
        AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY" \
        aws s3 ls "s3://$S3_BUCKET/smellpin/" | while read -r line; do
            local file_date=$(echo "$line" | awk '{print $1}')
            local file_name=$(echo "$line" | awk '{print $4}')
            
            if [[ "$file_date" < "$cutoff_date" ]]; then
                AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY" \
                AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY" \
                aws s3 rm "s3://$S3_BUCKET/smellpin/$file_name"
                log_info "Âà†Èô§S3ÊóßÂ§á‰ªΩ: $file_name"
            fi
        done
    fi
    
    log_success "ÊóßÂ§á‰ªΩÊ∏ÖÁêÜÂÆåÊàê"
}

# ÂÆåÊï¥Â§á‰ªΩ
full_backup() {
    log_info "ÂºÄÂßãÂÆåÊï¥Â§á‰ªΩ..."
    
    local db_backup=$(backup_database)
    local files_backup=$(backup_files)
    local config_backup=$(backup_config)
    
    # ‰∏ä‰º†Âà∞S3
    if [ -n "$db_backup" ]; then
        upload_to_s3 "$db_backup"
    fi
    
    if [ -n "$files_backup" ]; then
        upload_to_s3 "$files_backup"
    fi
    
    if [ -n "$config_backup" ]; then
        upload_to_s3 "$config_backup"
    fi
    
    # Ê∏ÖÁêÜÊóßÂ§á‰ªΩ
    cleanup_old_backups
    
    log_success "üéâ ÂÆåÊï¥Â§á‰ªΩÂÆåÊàêÔºÅ"
}

# Êï∞ÊçÆÂ∫ìÊÅ¢Â§ç
restore_database() {
    local backup_file="$1"
    
    if [ -z "$backup_file" ]; then
        log_error "ËØ∑ÊåáÂÆöÂ§á‰ªΩÊñá‰ª∂"
        exit 1
    fi
    
    if [ ! -f "$backup_file" ]; then
        log_error "Â§á‰ªΩÊñá‰ª∂‰∏çÂ≠òÂú®: $backup_file"
        exit 1
    fi
    
    log_warning "Âç≥Â∞ÜÊÅ¢Â§çÊï∞ÊçÆÂ∫ìÔºåËøôÂ∞ÜË¶ÜÁõñÁé∞ÊúâÊï∞ÊçÆÔºÅ"
    read -p "Á°ÆËÆ§ÁªßÁª≠Ôºü(y/N): " -n 1 -r
    echo
    
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "ÊÅ¢Â§çÊìç‰ΩúÂ∑≤ÂèñÊ∂à"
        exit 0
    fi
    
    log_info "ÂºÄÂßãÊÅ¢Â§çÊï∞ÊçÆÂ∫ì: $backup_file"
    
    # Ê£ÄÊü•Êï∞ÊçÆÂ∫ìÂÆπÂô®ÊòØÂê¶ËøêË°å
    if ! docker ps | grep -q "$DB_CONTAINER"; then
        log_error "Êï∞ÊçÆÂ∫ìÂÆπÂô® $DB_CONTAINER Êú™ËøêË°å"
        exit 1
    fi
    
    # ÂÅúÊ≠¢Â∫îÁî®ÊúçÂä°
    log_info "ÂÅúÊ≠¢Â∫îÁî®ÊúçÂä°..."
    docker-compose -f docker-compose.prod.yml stop backend
    
    # ÊÅ¢Â§çÊï∞ÊçÆÂ∫ì
    if [[ "$backup_file" == *.gz ]]; then
        gunzip -c "$backup_file" | docker exec -i "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME"
    else
        docker exec -i "$DB_CONTAINER" psql -U "$DB_USER" -d "$DB_NAME" < "$backup_file"
    fi
    
    if [ $? -eq 0 ]; then
        log_success "Êï∞ÊçÆÂ∫ìÊÅ¢Â§çÂÆåÊàê"
        
        # ÈáçÂêØÂ∫îÁî®ÊúçÂä°
        log_info "ÈáçÂêØÂ∫îÁî®ÊúçÂä°..."
        docker-compose -f docker-compose.prod.yml start backend
        
        log_success "üéâ Êï∞ÊçÆÂ∫ìÊÅ¢Â§çÂÆåÊàêÔºÅ"
    else
        log_error "Êï∞ÊçÆÂ∫ìÊÅ¢Â§çÂ§±Ë¥•"
        exit 1
    fi
}

# Êñá‰ª∂ÊÅ¢Â§ç
restore_files() {
    local backup_file="$1"
    
    if [ -z "$backup_file" ]; then
        log_error "ËØ∑ÊåáÂÆöÂ§á‰ªΩÊñá‰ª∂"
        exit 1
    fi
    
    if [ ! -f "$backup_file" ]; then
        log_error "Â§á‰ªΩÊñá‰ª∂‰∏çÂ≠òÂú®: $backup_file"
        exit 1
    fi
    
    log_warning "Âç≥Â∞ÜÊÅ¢Â§çÊñá‰ª∂ÔºåËøôÂ∞ÜË¶ÜÁõñÁé∞ÊúâÊñá‰ª∂ÔºÅ"
    read -p "Á°ÆËÆ§ÁªßÁª≠Ôºü(y/N): " -n 1 -r
    echo
    
    if [[ ! $REPLY =~ ^[Yy]$ ]]; then
        log_info "ÊÅ¢Â§çÊìç‰ΩúÂ∑≤ÂèñÊ∂à"
        exit 0
    fi
    
    log_info "ÂºÄÂßãÊÅ¢Â§çÊñá‰ª∂: $backup_file"
    
    # Â§á‰ªΩÁé∞ÊúâÊñá‰ª∂
    if [ -d "uploads" ]; then
        mv uploads "uploads.backup.$(date +%s)"
    fi
    
    # ÊÅ¢Â§çÊñá‰ª∂
    tar -xzf "$backup_file"
    
    log_success "üéâ Êñá‰ª∂ÊÅ¢Â§çÂÆåÊàêÔºÅ"
}

# ÂàóÂá∫Â§á‰ªΩ
list_backups() {
    log_info "Êú¨Âú∞Â§á‰ªΩÂàóË°®:"
    
    if [ -d "$BACKUP_DIR" ]; then
        ls -lh "$BACKUP_DIR"/*.{sql.gz,tar.gz} 2>/dev/null | while read -r line; do
            echo "  $line"
        done
    else
        log_warning "Â§á‰ªΩÁõÆÂΩï‰∏çÂ≠òÂú®"
    fi
    
    # S3Â§á‰ªΩÂàóË°®
    if [ -n "$S3_BUCKET" ] && command -v aws &> /dev/null; then
        log_info "S3Â§á‰ªΩÂàóË°®:"
        
        AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY" \
        AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY" \
        aws s3 ls "s3://$S3_BUCKET/smellpin/" | while read -r line; do
            echo "  $line"
        done
    fi
}

# ‰ªéS3‰∏ãËΩΩÂ§á‰ªΩ
download_from_s3() {
    local s3_key="$1"
    local local_file="$BACKUP_DIR/$(basename "$s3_key")"
    
    if [ -z "$S3_BUCKET" ] || [ -z "$S3_ACCESS_KEY" ] || [ -z "$S3_SECRET_KEY" ]; then
        log_error "S3ÈÖçÁΩÆ‰∏çÂÆåÊï¥"
        exit 1
    fi
    
    log_info "‰ªéS3‰∏ãËΩΩÂ§á‰ªΩ: $s3_key"
    
    AWS_ACCESS_KEY_ID="$S3_ACCESS_KEY" \
    AWS_SECRET_ACCESS_KEY="$S3_SECRET_KEY" \
    aws s3 cp "s3://$S3_BUCKET/smellpin/$s3_key" "$local_file"
    
    log_success "‰∏ãËΩΩÂÆåÊàê: $local_file"
    echo "$local_file"
}

# ‰∏ªÂáΩÊï∞
main() {
    case "$1" in
        "backup")
            case "$2" in
                "database")
                    backup_database
                    ;;
                "files")
                    backup_files
                    ;;
                "config")
                    backup_config
                    ;;
                "full"|"")
                    full_backup
                    ;;
                *)
                    log_error "Êú™Áü•ÁöÑÂ§á‰ªΩÁ±ªÂûã: $2"
                    exit 1
                    ;;
            esac
            ;;
        "restore")
            case "$2" in
                "database")
                    restore_database "$3"
                    ;;
                "files")
                    restore_files "$3"
                    ;;
                *)
                    log_error "Êú™Áü•ÁöÑÊÅ¢Â§çÁ±ªÂûã: $2"
                    exit 1
                    ;;
            esac
            ;;
        "list")
            list_backups
            ;;
        "download")
            download_from_s3 "$2"
            ;;
        "cleanup")
            cleanup_old_backups
            ;;
        *)
            show_help
            ;;
    esac
}

# ÊòæÁ§∫Â∏ÆÂä©‰ø°ÊÅØ
show_help() {
    echo "SmellPin Â§á‰ªΩÂíåÊÅ¢Â§çËÑöÊú¨"
    echo ""
    echo "‰ΩøÁî®ÊñπÊ≥ï:"
    echo "  $0 backup [Á±ªÂûã]              - ÊâßË°åÂ§á‰ªΩ"
    echo "  $0 restore <Á±ªÂûã> <Êñá‰ª∂>      - ÊâßË°åÊÅ¢Â§ç"
    echo "  $0 list                       - ÂàóÂá∫Â§á‰ªΩ"
    echo "  $0 download <S3Êñá‰ª∂Âêç>        - ‰ªéS3‰∏ãËΩΩÂ§á‰ªΩ"
    echo "  $0 cleanup                    - Ê∏ÖÁêÜÊóßÂ§á‰ªΩ"
    echo ""
    echo "Â§á‰ªΩÁ±ªÂûã:"
    echo "  full      - ÂÆåÊï¥Â§á‰ªΩÔºàÈªòËÆ§Ôºâ"
    echo "  database  - ‰ªÖÊï∞ÊçÆÂ∫ìÂ§á‰ªΩ"
    echo "  files     - ‰ªÖÊñá‰ª∂Â§á‰ªΩ"
    echo "  config    - ‰ªÖÈÖçÁΩÆÂ§á‰ªΩ"
    echo ""
    echo "ÊÅ¢Â§çÁ±ªÂûã:"
    echo "  database  - ÊÅ¢Â§çÊï∞ÊçÆÂ∫ì"
    echo "  files     - ÊÅ¢Â§çÊñá‰ª∂"
    echo ""
    echo "Á§∫‰æã:"
    echo "  $0 backup                     - ÂÆåÊï¥Â§á‰ªΩ"
    echo "  $0 backup database            - ‰ªÖÂ§á‰ªΩÊï∞ÊçÆÂ∫ì"
    echo "  $0 restore database backup.sql.gz  - ÊÅ¢Â§çÊï∞ÊçÆÂ∫ì"
    echo "  $0 list                       - ÂàóÂá∫ÊâÄÊúâÂ§á‰ªΩ"
    echo "  $0 cleanup                    - Ê∏ÖÁêÜ30Â§©ÂâçÁöÑÂ§á‰ªΩ"
}

# Ê£ÄÊü•ÂèÇÊï∞
if [ $# -eq 0 ]; then
    show_help
    exit 0
fi

# ÊâßË°å‰∏ªÂáΩÊï∞
main "$@"